{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/customer_inquiries.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to understand its structure\n",
        "data.head(), data.info()"
      ],
      "metadata": {
        "id": "lylu4hh19RTi",
        "outputId": "d5729155-fa90-4fe0-c0c5-47c507b36270",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1113 entries, 0 to 1112\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Complaint  1113 non-null   object\n",
            " 1   Category   1113 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 17.5+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                           Complaint Category\n",
              " 0  I was overcharged on my last bill; the amount ...  Billing\n",
              " 1  The discount I applied didn’t reflect on my in...  Billing\n",
              " 2  Why am I being charged twice for the same prod...  Billing\n",
              " 3  My billing statement has hidden fees I didn’t ...  Billing\n",
              " 4  I need an explanation for the unexpected incre...  Billing,\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Check the cleaned data\n",
        "data_cleaned.info(), data_cleaned.head()"
      ],
      "metadata": {
        "id": "WYD1jARZ9UqS",
        "outputId": "492a7aa3-8286-4cac-a2de-2fd5a52ad3f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1113 entries, 0 to 1112\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Complaint  1113 non-null   object\n",
            " 1   Category   1113 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 17.5+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "                                            Complaint Category\n",
              " 0  I was overcharged on my last bill; the amount ...  Billing\n",
              " 1  The discount I applied didn’t reflect on my in...  Billing\n",
              " 2  Why am I being charged twice for the same prod...  Billing\n",
              " 3  My billing statement has hidden fees I didn’t ...  Billing\n",
              " 4  I need an explanation for the unexpected incre...  Billing)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Text preprocessing: Remove special characters, tokenize, remove stopwords, and apply lemmatization\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Handle common misspellings or typos (e.g., 'wont' -> 'will not')\n",
        "    text = re.sub(r'\\bim\\b', 'i am', text)\n",
        "    text = re.sub(r'\\bwont\\b', 'will not', text)\n",
        "    text = re.sub(r'\\bdont\\b', 'do not', text)\n",
        "    text = re.sub(r'\\bcant\\b', 'cannot', text)\n",
        "    text = re.sub(r'\\bdoesnt\\b', 'does not', text)\n",
        "\n",
        "    # Remove repeated characters (e.g., \"loooove\" to \"love\")\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
        "\n",
        "    # Tokenization, stopword removal, and lemmatization\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
        "\n",
        "    # Rejoin words into a clean text\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing to the 'Complaint' column\n",
        "data_cleaned['Complaint'] = data_cleaned['Complaint'].apply(preprocess_text)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data_cleaned['Complaint']\n",
        "y = data_cleaned['Category']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "TfidfVectorizer(max_features=15000, ngram_range=(1, 4), min_df=2, max_df=0.9, sublinear_tf=True)\n",
        "\n",
        "TfidfVectorizer(\n",
        "    max_features=15000,\n",
        "    ngram_range=(1, 3),\n",
        "    analyzer='word',\n",
        "    strip_accents='unicode',\n",
        "    lowercase=True,\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "# Combine word and character n-grams\n",
        "TfidfVectorizer(\n",
        "    max_features=15000,\n",
        "    ngram_range=(1, 3),\n",
        "    analyzer='char_wb',  # Character n-grams within word boundaries\n",
        ")\n",
        "\n",
        "# Build a pipeline with TF-IDF and Logistic Regression\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=15000, ngram_range=(1, 3), min_df=2, max_df=0.9,smooth_idf=True, sublinear_tf=True)),  # TF-IDF Vectorizer with bigrams\n",
        "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))  # Logistic Regression with increased max iterations\n",
        "])\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'tfidf__max_features': [10000, 15000, 20000],\n",
        "    'clf__C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "accuracy, report\n"
      ],
      "metadata": {
        "id": "Qfs2fxtD9bYv",
        "outputId": "2fbb6610-1c9e-43c6-bea9-a152a38919b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8709677419354839,\n",
              " '                   precision    recall  f1-score   support\\n\\n   Account Issues       0.89      0.94      0.91        33\\n          Billing       1.00      0.89      0.94        36\\n  Delivery Issues       0.87      0.81      0.84        32\\n    Miscellaneous       0.93      0.65      0.76        20\\n     Order Issues       0.75      0.90      0.82        30\\n   Product Issues       0.74      0.71      0.73        28\\n          Quality       0.86      0.86      0.86        28\\n           Refund       0.85      1.00      0.92        17\\nTechnical Support       0.90      0.93      0.92        30\\n         Warranty       0.96      1.00      0.98        25\\n\\n         accuracy                           0.87       279\\n        macro avg       0.87      0.87      0.87       279\\n     weighted avg       0.88      0.87      0.87       279\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# Assuming 'model' is your trained model\n",
        "with open('best_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_model, file)"
      ],
      "metadata": {
        "id": "K-Xp9PPIBkM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('best_model.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)  # Ensure no errors here"
      ],
      "metadata": {
        "id": "zHgucRiIEQLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_category(inquiry, model=best_model):\n",
        "  \"\"\"Predicts the category of a user's inquiry using the trained model.\"\"\"\n",
        "  preprocessed_inquiry = preprocess_text(inquiry)\n",
        "  predicted_category = model.predict([preprocessed_inquiry])[0]\n",
        "  return predicted_category\n",
        "\n",
        "\n",
        "# Get user input\n",
        "user_inquiry = input(\"Please enter your inquiry: \")\n",
        "\n",
        "# Predict the category\n",
        "predicted_category = predict_category(user_inquiry)\n",
        "\n",
        "# Output the predicted category\n",
        "print(\"Predicted Category:\", predicted_category)"
      ],
      "metadata": {
        "id": "Ivv5ctW5-E4O",
        "outputId": "3f623daa-9716-4363-a966-31e88592ef57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your inquiry: my subscription isues\n",
            "Predicted Category: Billing\n"
          ]
        }
      ]
    }
  ]
}